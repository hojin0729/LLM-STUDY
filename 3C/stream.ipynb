{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2427e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large Language Model(LLM)에 대한 공부 계획을 세워드리겠습니다. 이 계획은 4주 동안 진행되며, 매주 주제를 나누어 학습할 수 있도록 구성하였습니다.\n",
      "\n",
      "### 1주차: LLM의 기초 이해\n",
      "- **목표**: LLM의 기본 개념과 역사 이해\n",
      "- **학습 내용**:\n",
      "  - LLM의 정의 및 특징\n",
      "  - 자연어 처리(NLP)의 기본 개념\n",
      "  - LLM의 발전 역사 (예: GPT, BERT 등)\n",
      "- **추천 자료**:\n",
      "  - \"Attention is All You Need\" 논문 읽기\n",
      "  - 관련 유튜브 강의 시청 (예: LLM 개요)\n",
      "- **과제**: LLM의 발전 과정을 정리한 요약 작성\n",
      "\n",
      "### 2주차: LLM의 구조와 작동 원리\n",
      "- **목표**: LLM의 내부 구조와 작동 원리 이해\n",
      "- **학습 내용**:\n",
      "  - Transformer 아키텍처의 구성 요소 (Self-Attention, Feedforward Network 등)\n",
      "  - 학습 과정 (Pre-training vs Fine-tuning)\n",
      "  - Tokenization과 Embedding\n",
      "- **추천 자료**:\n",
      "  - \"The Illustrated Transformer\" 블로그 포스트\n",
      "  - 관련 강의 (예: Stanford CS224N)\n",
      "- **과제**: Transformer 구조를 그림으로 그려보고 설명하기\n",
      "\n",
      "### 3주차: LLM의 응용 및 사례\n",
      "- **목표**: LLM의 다양한 응용 사례 이해\n",
      "- **학습 내용**:\n",
      "  - LLM을 활용한 텍스트 생성, 번역, 요약 등\n",
      "  - 실제 사례 연구 (예: OpenAI의 GPT, Google의 BERT)\n",
      "  - LLM의 한계와 윤리적 고려사항\n",
      "- **추천 자료**:\n",
      "  - LLM을 활용한 프로젝트 사례 조사\n",
      "  - 관련 논문 및 기사 읽기\n",
      "- **과제**: LLM의 응용 사례를 정리하고, 자신의 의견 작성\n",
      "\n",
      "### 4주차: LLM의 최신 동향 및 미래 전망\n",
      "- **목표**: LLM의 최신 동향과 미래 전망 이해\n",
      "- **학습 내용**:\n",
      "  - 최신 LLM 모델 (예: GPT-4, ChatGPT 등)\n",
      "  - LLM의 발전 방향과 연구 트렌드\n",
      "  - LLM의 사회적 영향 및 윤리적 문제\n",
      "- **추천 자료**:\n",
      "  - 최신 연구 논문 및 기술 블로그\n",
      "  - 관련 컨퍼런스 발표 자료\n",
      "- **과제**: LLM의 미래에 대한 자신의 예측 및 의견 작성\n",
      "\n",
      "### 추가 팁\n",
      "- 매주 학습한 내용을 정리하고, 스터디 그룹이나 포럼에서 토론해보세요.\n",
      "- 실습을 통해 LLM을 직접 사용해보는 것도 좋은 경험이 될 것입니다. (예: Hugging Face의 Transformers 라이브러리 활용)\n",
      "\n",
      "이 계획을 통해 LLM에 대한 깊이 있는 이해를 쌓을 수 있기를 바랍니다!"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# chatgpt 모델 호출\n",
    "\n",
    "chat = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"당신은 공부 계획을 세워주는 스터디 플래너 머신입니다.\"\n",
    "                \"사용자의 공부 주제를 입력받으면, 이를 학습하기 위한 공부 계획을 작성합니다.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(text=\"Large Language Model에 대해서 공부하고 싶어요.\")\n",
    "\n",
    "for chunk in chat.stream(messages):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166164b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
